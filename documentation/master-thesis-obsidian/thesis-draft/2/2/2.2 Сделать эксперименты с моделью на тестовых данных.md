Алгоритм сбора датасета для автоматизации отбора кандидатов предполагает последовательное извлечение, обработку и структурирование данных из резюме и вакансий. Первым этапом осуществляется сбор данных через платформы, где соискатели подают резюме на вакансии, а HR специалисты принимают решения о приглашении или отказе. На втором этапе анализируются события, такие как «приглашен» или «отклонен», чтобы выделить уникальные пары «резюме-вакансия» и устранить дубли, где одно резюме попадало в обе группы. Далее данные очищаются от пропусков и получают актуальные на момент отклика заголовки вакансий и резюме. Завершается процесс преобразованием данных в формат, подходящий для машинного обучения, с учетом баланса классов и конфиденциальности информации​

Соискатели присылают свои резюме на вакансии после чего hr может принять/отклонить/ничего не сделать. Рассмотрим только случаи где hr что то сделал так как если hr ничего не сделал то мы не можем однозначно сказать подходит или не подходит данное резюме для вакансии.

Напишем запрос для того чтобы получить события «пригласил» или «отклонил». После чего оценим количество событий. 

|   |   |   |
|---|---|---|
|Тип события|Количество событий|Процентное соотношение количества событий|
|пригласил|157414|52%|
|отклонил|142799|48%|

Таблица 1 – Количество событий по типам

Суммарно имеем 300213 событий. Есть дисбаланс классов, но не большой, разница 2%.

Теперь посмотрим количество уникальных пар резюме вакансия в каждом типе события «пригласил» или «отклонил».

|   |   |   |
|---|---|---|
|Тип события|Количество уникальных пар резюме-вакансия|Процентное соотношение количеств уникальных пар резюме-вакансия|
|пригласил|140284|51%|
|отклонил|136920|49%|

Таблица 2 – Количество событий по типам

Как видно теперь получается более лучший баланс классов, это намекает на то что среди принятых резюме было больше дублей пар вакансия-резюме, так как дизбаланс классов уменьшился на 1% за счёт типа события «пригласил». Оценим сколько пар резюме-вакансия попали в обе группы. Всего уникальных пар 267493, а сумма при распределении на пары резюме-вакансия 277204, что говорит о том что есть 9711 случаев попадания в обе группы. После перепроверки отдельным запросом совпало, что 9711 уникальных пар резюме-вакансия попали в обе группы. Их мы исключим из датасета поскольку они неоднозначно подходили на вакансию эти данные могут добавить дополнительную дисперсию в наш датасет, что нам не нужно. Как один из вариантов когда так происходило, например, hr случайно переместил не в ту папку отклик. Тогда рассчитаем количественные характеристики после того как уберём те варианты которые попали в обе группы.

|   |   |   |
|---|---|---|
|Тип события|Количество уникальных пар резюме-вакансия|Процентное соотношение количеств уникальных пар резюме-вакансия|
|пригласил|130578|51%|
|отклонил|127231|49%|

Таблица 3 – Количество событий по типам

Соискатель с одним и тем же резюме  может несколько раз откликнуться на одну и ту же вакансию так что будем брать дату и время последнего отклика резюме на вакансию.

Теперь выгрузим датафрейм в формате (resume_id, vacancy_id, type_name, event_date_l) где уберём пары резюме-вакансия которые попадают в обе группы и возьмём последнее время отклика, также убираем строки где есть null.

Теперь нужно получить актуальные заголовки резюме и вакансий в момент отклика. После получения актуальных на момент отклика заголовков вакансий получилось уже 193825 записей в датасете. Теперь добавим актульные на момент отклика заголовки резюме. И после этого получаем 172321 строк. Посмотрим теперь распределение классов.

|   |   |   |
|---|---|---|
|Тип события|Количество|Процентное соотношение количеств|
|пригласил|75283|44%|
|отклонил|97038|56%|

Таблица 4 – Количество событий по типам

Теперь есть смещение классов в сторону отклонил на 6%. Теперь датасет можно переносить в csv. Можно отметить, что здесь информационная безопасность обеспечивается с точки зрения данных тем что в названии вакансии или резюме не пишут персональную информацию, а если и пишут в заголовок резюме, то модератор системы её удаляет. Так что никакой опасности утечки персональных данных нет — название вакансии на которую откликнулся человек не является персональной информацией, а название профессии не является информацией по которой можно идентифицировать человека. 

После анализа датасета выяснилось, что есть случаи, когда название должности вакансии соответствует названию резюме, но резюме всё равно отклонили это значит, что есть причина отклонения помимо названия вакансии. Это мы учтём при дальнейшей обработки данных. Далее загрузим данные в google collab.

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdn9zItUPeqbPR102x0VoCX_iHvuwTGObEUyDSQIjL630W8p5CUbOivbGo5XVpTq9reffdoV6AOdGgEaoZ_KCmPZc8UNX3EIisdy8f5vcEVJimlQYdFbOere_Dl82IGMOk-RRbhaurgSp2SpcZ4qXc?key=YgP9hAqfvH38H8iaDtkTzAt7)

Рисунок 1 – Датасет заголовки вакансий и резюме по типу события

Далее был проведён этап токенизации с использованием предобученного токенизатора модели BERT. Текстовые данные были преобразованы в числовой формат, включающий индексы токенов, маски внимания и сегментные индикаторы. После этого данные были разделены на батчи для более эффективной обработки на GPU.

На этапе обучения была инициализирована модель BERT с головой классификации. Обучение проводилось с использованием оптимизатора AdamW и планировщика обучения с линейным уменьшением скорости обучения. Для контроля переобучения использовались метрики точности на валидационном наборе данных. После завершения обучения модель показала улучшенные результаты классификации на тестовых данных. В приложении 1 есть подробный листинг процесса обучения BERT.

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfdQ6HBOizRTF9ZzAaFLiMfn3KE5WB0ZqnXr0q-NfQiNH2O_Bh8p6g-qCigoJyVDv9zbXfKV-x7InhKj3mkMHblQ3rXJwCsBM_yucjhoUsx7DGvkYtQQcHaEIGhC-XRnMbLkGxttt4Mm64euWvqueQ?key=YgP9hAqfvH38H8iaDtkTzAt7)

Рисунок 2 – BERT fine-tuning для классификации по эпохам

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeVwq0QD_cZLqUVPtiy30oXG_wiKDyqgkVjmmeHiYMPknSxrjdsZrUQVcX9BZBGEswHNxvz9NqvzWWkYZuk4a8Ck46LgZuI_RCETyM6lzTvnbSG-rmwQh6hFxWkrmDvMyyA-mTjiIf8DvTwxnz6YMQ?key=YgP9hAqfvH38H8iaDtkTzAt7)

Рисунок 3 – график BERT fine-tuning для классификации по эпохам

Как видно на графике переобуение наступает после второй эпохи обучения, что говорит о том, что достаточно двух эпох, чтобы сделать fine-tuning модели на наших данных.

В итоге получена модель обладающая точностью классификации на два класса составляющая по метрике accuracy 0.75.

Также в качестве метрики был взят Коэффициент корреляции Мэтьюса (Matthews correlation coefficient, сокращенно MCC [29]). Используют данную метрику, так как у нас есть несбалансированность классов в данных. Получаем MCC на всей выборке равный 0.550, что говорит о том, что модель предсказывает класс не случаеным образом. MCC принимает значения между -1 и 1, где 0 означает случайное предсказание оно не зависит от входных данных -1, проставили всем семплам неверные метки, а 1 наоборот верные. 

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcaUleUNnis6-EEr-sI8QjxjQAH8RYqNjZzxVKs9Aip1MdqkSnGQJFAPItCT0FzVLLf9HE38skWSwRlyHun0W2vt9koLmqPKo4shASMuXPgU_CCJ2hstjXOihZ_bqMNRRoN4Hx10eEnhs-6jtM2Kgk?key=YgP9hAqfvH38H8iaDtkTzAt7)

Рисунок 4 – диаграмма метрика MCC по батчам тестового датасета